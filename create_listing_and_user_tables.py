"""
Create user and listing tables with JSON support in PostgreSQL using SQLAlchemy Core and asyncpg
=== TABLES CREATED ===
1. users - User profiles and authentication data
2. listings - Main swap items with JSON category data
3. Indexes - Performance indexes for fast searching and filtering


=== ARCHITECTURE CONTEXT ===
This code is part of a SPEED + SECURITY focused architecture for the SwapWithUs platform.

1. SCHEMA DEFINITION (SQLAlchemy Core):
   - Defines table structures with proper data types
   - Provides type safety and validation at schema level
   - JSON fields for flexible category-specific data storage
   - Cross-database compatibility for future scaling
2. TABLE CREATION (Pure asyncpg):
   - Executes CREATE TABLE statements using asyncpg for speed
   - Creates performance indexes including JSON-specific GIN indexes
   - Handles PostgreSQL extensions (uuid-ossp for UUID generation)
   - Direct SQL execution without ORM overhead    
3. PERFORMANCE OPTIMIZATIONS:
   - JSONB fields for fast JSON querying in PostgreSQL
   - Strategic indexes on frequently queried fields
   - UUID primary keys for security and distributed systems
   - Optimized for swap platform's read-heavy workload
=== WHY THIS APPROACH FOR SWAPWITHUS.COM ===
- Scales with business growth (Airbnb-style platform needs performance)   

"""


import os
import urllib.parse
from sqlalchemy import (
    MetaData, Table, Column, Integer, String, DateTime, Boolean, Text,
    func, DECIMAL, DATE, UUID, ARRAY, ForeignKey
)
from sqlalchemy.dialects.postgresql import JSONB, INET
from sqlalchemy.schema import CreateTable
from sqlalchemy.dialects import postgresql
import asyncpg
import asyncio
import json
from typing import Dict, List, Optional, Any
from uuid import uuid4

from connection_to_db import get_db_connection

import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# SQLAlchemy metadata for schema definition only (NO connections)
metadata = MetaData()

# Users table definition
users_table = Table('users', metadata,
    Column('id', Integer, primary_key=True, autoincrement=True),
    Column('user_uuid', UUID, nullable=False, unique=True, server_default=func.gen_random_uuid()),
    Column('firebase_uid', String(128), unique=True),
    Column('email', String(255), unique=True, nullable=False),
    Column('email_verified', Boolean, default=False),
    Column('first_name', String(100)),
    Column('last_name', String(100)),
    Column('phone', String(50)),
    Column('avatar_url', String(500)),
    Column('account_status', String(50), default='active'),
    Column('trust_score', Integer, default=0),
    Column('verification_level', String(50), default='unverified'),
    Column('created_at', DateTime, nullable=False, server_default=func.current_timestamp()),
    Column('updated_at', DateTime, server_default=func.current_timestamp()),
    Column('deleted_at', DateTime)
)

# Main listings table with JSON category data (following  architecture)
listings_table = Table('listings', metadata,
    # Primary identification
    Column('id', Integer, primary_key=True, autoincrement=True),
    Column('listing_uuid', UUID, nullable=False, unique=True, server_default=func.gen_random_uuid()),

    # User reference
    Column('owner_id', Integer, ForeignKey('users.id'), nullable=False),  # FK to users.id
    Column('firebase_uid', String(128)),

    # Basic listing info
    Column('title', String(255), nullable=False),
    Column('description', Text, nullable=False),
    Column('category', String(50), nullable=False),  # homes, clothes, books, etc.
    Column('condition', String(50), nullable=False, default='good'),

    # Location
    Column('city', String(100), nullable=False),
    Column('country', String(100), nullable=False),
    Column('address', Text),
    Column('latitude', DECIMAL(10, 8)),
    Column('longitude', DECIMAL(11, 8)),

    # Availability
    Column('available_from', DATE),
    Column('available_until', DATE),
    Column('value_estimate', String(50)),
    Column('preferred_swap_categories', ARRAY(String)),  # Array of categories

    # Contact info
    Column('contact_name', String(255), nullable=False),
    Column('contact_email', String(255), nullable=False),
    Column('contact_phone', String(50)),

    # Media
    Column('photos', ARRAY(String)),  # Array of photo URLs
    Column('main_photo', String(500)),

    # *** KEY: JSON field for category-specific data ***
    Column('category_data', JSONB),  # All category-specific fields as JSON

    # Status & moderation
    Column('status', String(50), nullable=False, default='active'),
    Column('moderation_status', String(50), default='approved'),
    Column('is_featured', Boolean, default=False),

    # Analytics
    Column('view_count', Integer, default=0),
    Column('inquiry_count', Integer, default=0),
    Column('last_activity', DateTime, server_default=func.current_timestamp()),

    # SEO
    Column('slug', String(300), unique=True),
    Column('search_tags', ARRAY(String)),

    # Audit trail
    Column('created_at', DateTime, nullable=False, server_default=func.current_timestamp()),
    Column('updated_at', DateTime, server_default=func.current_timestamp()),
    Column('deleted_at', DateTime),
    Column('created_by_ip', INET),
    Column('last_modified_by', Integer, ForeignKey('users.id'))
)


# Create tables using  SQLAlchemy Core + asyncpg approach
async def create_users_table():
    """Create users table using SQLAlchemy Core + asyncpg execution"""
    create_sql = str(CreateTable(users_table).compile(dialect=postgresql.dialect()))
    logging.info(f"Create Users Table SQL: {create_sql}")
    

    conn = await get_db_connection()
    try:
        await conn.execute("CREATE EXTENSION IF NOT EXISTS \"uuid-ossp\";")  # For UUID support
        await conn.execute(create_sql)
        print("âœ… Users table created using SQLAlchemy Core + asyncpg")
    except Exception as e:
        print(f"âŒ Users table creation failed: {e}")
    finally:
        await conn.close()

async def create_listings_table():
    """Create listings table with JSON support using SQLAlchemy Core + asyncpg"""
    create_sql = str(CreateTable(listings_table).compile(dialect=postgresql.dialect()))
    logging.info(f"Create Listings Table SQL: {create_sql}")

    conn = await get_db_connection()
    try:
        await conn.execute(create_sql)

        # All indexes are now created in create_all_indexes() function for better organization
        # This keeps table creation and indexing separate for maintainability

        print("âœ… Listings table with JSON support created using SQLAlchemy Core + asyncpg")
        print("ğŸ“‹ Note: Run create_all_indexes() to add performance indexes")

    except Exception as e:
        print(f"âŒ Listings table creation failed: {e}")
    finally:
        await conn.close()

async def create_essential_indexes():
    """
    ğŸš€ STARTUP PHASE: Essential indexes for basic SwapWithUs functionality
    
    These are REQUIRED for your platform to work without being slow.
    Create these first - your app won't perform well without them.
    
    When to run: Day 1 of deployment
    Performance impact: 100x faster basic queries
    Storage cost: Minimal
    """
    essential_indexes = [
        # Basic category filtering (CRITICAL - every query uses this)
        "CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_listings_category ON listings(category);",
        
        # JSON performance (CRITICAL - without this JSON queries take seconds)  
        "CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_listings_category_data_gin ON listings USING GIN(category_data);",
        
        # User dashboard (CRITICAL - users need to see their listings)
        "CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_listings_owner_status ON listings(owner_id, status);",
        
        # Homepage latest listings (CRITICAL - main page loads fast)
        "CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_listings_active_created ON listings(created_at DESC) WHERE status = 'active';",
        
        # Basic location search (CRITICAL - most common search pattern)
        "CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_listings_city_category ON listings(city, category) WHERE status = 'active';",
    ]

    conn = await get_db_connection()
    try:
        logging.info("ğŸš€ Creating ESSENTIAL indexes for SwapWithUs startup...")
        
        for i, index_sql in enumerate(essential_indexes, 1):
            try:
                logging.info(f"[{i}/{len(essential_indexes)}] Creating: {index_sql[:60]}...")
                await conn.execute(index_sql)
                logging.info("âœ… Success")
            except Exception as e:
                logging.error(f"âŒ Failed: {e}")

        logging.info("âœ… Essential startup indexes created!")
        print("âœ… ESSENTIAL indexes created - your platform is ready for basic usage!")
        print(f"ğŸ“Š Essential indexes: {len(essential_indexes)}")

    except Exception as e:
        logging.error(f"âŒ Essential indexing failed: {e}")
        print(f"âŒ Essential indexing failed: {e}")
    finally:
        await conn.close()

async def create_growth_indexes():
    """
    ğŸ“ˆ GROWTH PHASE: Nice-to-have indexes for better user experience
    
    Add these when you have 1000+ listings or users complain about speed.
    These improve user experience but aren't critical for basic functionality.
    
    When to run: After 1-2 months, when you have real users
    Performance impact: 5-10x faster advanced queries  
    Storage cost: Moderate
    """
    growth_indexes = [
        # Firebase authentication (when you have many users)
        "CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_listings_firebase_uid ON listings(firebase_uid);",
        
        # Featured content (when you start featuring listings)
        "CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_listings_featured_created ON listings(is_featured DESC, created_at DESC) WHERE status = 'active';",
        
        # Country-level search (when you expand internationally)
        "CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_listings_country_category ON listings(country, category) WHERE status = 'active';",
        
        # Popular category filters (when you have enough data to see patterns)
        "CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_listings_homes_bedrooms ON listings((category_data->>'bedrooms')) WHERE category = 'homes';",
        "CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_listings_clothes_size ON listings((category_data->>'size')) WHERE category = 'clothes';",
        "CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_listings_books_author ON listings((category_data->>'author')) WHERE category = 'books';",
        
        # Analytics (when you want to show "most popular" content)
        "CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_listings_view_count ON listings(view_count DESC) WHERE status = 'active';",
        "CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_listings_last_activity ON listings(last_activity DESC);",
    ]

    conn = await get_db_connection()
    try:
        logging.info("ğŸ“ˆ Creating GROWTH indexes for better user experience...")
        
        for i, index_sql in enumerate(growth_indexes, 1):
            try:
                logging.info(f"[{i}/{len(growth_indexes)}] Creating: {index_sql[:60]}...")
                await conn.execute(index_sql)
                logging.info("âœ… Success")
            except Exception as e:
                logging.error(f"âŒ Failed: {e}")

        logging.info("âœ… Growth phase indexes created!")
        print("âœ… GROWTH indexes created - improved user experience unlocked!")
        print(f"ğŸ“Š Growth indexes: {len(growth_indexes)}")

    except Exception as e:
        logging.error(f"âŒ Growth indexing failed: {e}")
        print(f"âŒ Growth indexing failed: {e}")
    finally:
        await conn.close()

async def create_advanced_indexes():
    """
    ğŸ¢ SCALE PHASE: Advanced indexes for enterprise-level features
    
    Add these when you have 10,000+ listings and want professional features.
    These enable advanced functionality like full-text search and detailed filtering.
    
    When to run: When you're ready to compete with Airbnb-level features
    Performance impact: Enables features impossible without these indexes
    Storage cost: Higher, but worth it for advanced features
    """
    advanced_indexes = [
        # Full-text search (professional Google-like search)
        "CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_listings_fulltext ON listings USING GIN(to_tsvector('english', title || ' ' || description));",
        
        # Advanced homes filtering (detailed property search)
        "CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_listings_homes_bathrooms ON listings(((category_data->>'bathrooms')::numeric)) WHERE category = 'homes';",
        "CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_listings_homes_guests ON listings(((category_data->>'max_guests')::integer)) WHERE category = 'homes';",
        "CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_listings_homes_amenities ON listings USING GIN((category_data->'amenities')) WHERE category = 'homes';",
        
        # Advanced clothes filtering (fashion marketplace features)
        "CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_listings_clothes_brand ON listings((category_data->>'brand')) WHERE category = 'clothes';",
        "CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_listings_clothes_gender ON listings((category_data->>'gender')) WHERE category = 'clothes';",
        
        # Advanced books filtering (detailed book search)
        "CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_listings_books_genre ON listings((category_data->>'genre')) WHERE category = 'books';",
        
        # Electronics marketplace features
        "CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_listings_electronics_brand ON listings((category_data->>'brand')) WHERE category = 'electronics';",
        "CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_listings_electronics_model ON listings((category_data->>'model')) WHERE category = 'electronics';",
        
        # Sports equipment filtering  
        "CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_listings_sports_sport ON listings((category_data->>'sport')) WHERE category = 'sports';",
        
        # Vehicle marketplace features
        "CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_listings_vehicles_make ON listings((category_data->>'make')) WHERE category = 'vehicles';",
        
        # Services marketplace
        "CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_listings_services_type ON listings((category_data->>'service_type')) WHERE category = 'services';",
    ]

    conn = await get_db_connection()
    try:
        logging.info("ğŸ¢ Creating ADVANCED indexes for enterprise-level features...")
        
        for i, index_sql in enumerate(advanced_indexes, 1):
            try:
                logging.info(f"[{i}/{len(advanced_indexes)}] Creating: {index_sql[:60]}...")
                await conn.execute(index_sql)
                logging.info("âœ… Success")
            except Exception as e:
                logging.error(f"âŒ Failed: {e}")

        logging.info("âœ… Advanced enterprise indexes created!")
        print("âœ… ADVANCED indexes created - enterprise-level features enabled!")
        print(f"ğŸ“Š Advanced indexes: {len(advanced_indexes)}")

    except Exception as e:
        logging.error(f"âŒ Advanced indexing failed: {e}")
        print(f"âŒ Advanced indexing failed: {e}")
    finally:
        await conn.close()

async def create_all_indexes():
    """
    ğŸš€ Create ALL indexes at once (for production-ready deployment)
    
    This runs all three phases: Essential + Growth + Advanced
    Use this when you want full platform capability from day 1.
    """
    print("ğŸš€ Creating ALL SwapWithUs indexes (Essential + Growth + Advanced)...")
    await create_essential_indexes()
    await create_growth_indexes() 
    await create_advanced_indexes()
    print("ğŸ‰ COMPLETE! Your SwapWithUs platform is fully optimized and ready to scale!")
        
if __name__ == "__main__":
    # Run complete database setup for SwapWithUs platform
    asyncio.run(create_users_table())
    asyncio.run(create_listings_table())
    asyncio.run(create_all_indexes())  # Create ALL performance indexes in one organized method
